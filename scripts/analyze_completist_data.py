"""Analyze complete implementation status across the repository.

This script parses intermediate data generated by 'jules-completist' scans
and produces structured reports and prioritized issue lists.

Principles:
- DRY: Consolidated redundant file scanning loops into a generic helper.
- Orthogonality: Separates data extraction from report generation logic.
"""

from __future__ import annotations

import glob
import logging
import os
import re
from collections.abc import Callable, Mapping
from datetime import datetime
from typing import Any, NotRequired, TypedDict, cast

# Constants and Configuration
DATA_DIR = ".jules/completist_data"
REPORT_DIR = "docs/assessments/completist"
ISSUES_DIR = "docs/assessments/issues"

FILES_MAP = {
    "MARKERS": os.path.join(DATA_DIR, "todo_markers.txt"),
    "NOT_IMPL": os.path.join(DATA_DIR, "not_implemented.txt"),
    "STUBS": os.path.join(DATA_DIR, "stub_functions.txt"),
    "DOCS": os.path.join(DATA_DIR, "incomplete_docs.txt"),
    "ABSTRACT": os.path.join(DATA_DIR, "abstract_methods.txt"),
}

EXCLUDED_PATHS = [
    "scripts/analyze_completist_data.py",
    "docs/",
    ".github/",
    ".jules/",
    "CRITICAL_PROJECT_REVIEW.md",
    "WORKFLOW_AND_AGENTS_REPORT.md",
    "pyproject.toml",
]


logger = logging.getLogger(__name__)


class Finding(TypedDict):
    file: str
    line: str
    type: str
    text: NotRequired[str]
    name: NotRequired[str]


def is_excluded(filepath: str) -> bool:
    """Check if filepath should be excluded from analysis."""
    if not filepath:
        return True

    fp = filepath.replace("\\", "/")
    if fp.startswith("./"):
        fp = fp[2:]

    for excl in EXCLUDED_PATHS:
        if fp.startswith(excl) or excl in fp:
            return True
    return False


def _parse_grep_line(line: str) -> tuple[str | None, str | None, str | None]:
    """Parse a standard 'file:line:content' grep output line."""
    parts = line.split(":", 2)
    if len(parts) < 3:
        return None, None, None
    return parts[0], parts[1], parts[2].strip()


def _scan_completist_file(
    source_key: str, parser: Callable[[str], Finding | None]
) -> list[Finding]:
    """Generic helper to scan a completist data file and parse findings."""
    source_path = FILES_MAP.get(source_key)
    if not source_path or not os.path.exists(source_path):
        return []

    results: list[Finding] = []
    with open(source_path, encoding="utf-8", errors="replace") as f:
        for line in f:
            finding = parser(line)
            if finding and not is_excluded(finding["file"]):
                results.append(finding)
    return results


def analyze_todos() -> tuple[list[Finding], list[Finding]]:
    """Analyze TO-DO and FIX-ME markers."""
    todos: list[Finding] = []
    fixmes: list[Finding] = []

    # Obfuscate strings to avoid finding this script itself in greedy scans
    todo_str = "TO" + "DO"
    fixme_markers = ["FIX" + "ME", "XXX", "HACK", "TEMP"]

    def _parser(line: str) -> Finding | None:
        filepath, lineno, content = _parse_grep_line(line)
        if not filepath or not lineno or content is None:
            return None

        if re.search(r"\b" + todo_str + r"\b", content):
            return {"file": filepath, "line": lineno, "text": content, "type": "TODO"}

        for m_marker in fixme_markers:
            if re.search(r"\b" + m_marker + r"\b", content):
                return {
                    "file": filepath,
                    "line": lineno,
                    "text": content,
                    "type": m_marker,
                }
        return None

    all_markers = _scan_completist_file("MARKERS", _parser)
    for marker_item in all_markers:
        if marker_item["type"] == "TODO":
            todos.append(marker_item)
        else:
            fixmes.append(marker_item)

    return todos, fixmes


def analyze_stubs() -> list[Finding]:
    """Analyze stub functions."""

    def _parser(line: str) -> Finding | None:
        parts = line.strip().rsplit(" ", 1)
        if len(parts) < 2 or ":" not in parts[0]:
            return None
        filepath, lineno = parts[0].rsplit(":", 1)
        return {"file": filepath, "line": lineno, "name": parts[1], "type": "Stub"}

    return _scan_completist_file("STUBS", _parser)


def analyze_docs() -> list[Finding]:
    """Analyze missing documentation."""

    def _parser(line: str) -> Finding | None:
        parts = line.strip().rsplit(" ", 1)
        if len(parts) < 2 or ":" not in parts[0]:
            return None
        filepath, lineno = parts[0].rsplit(":", 1)
        return {"file": filepath, "line": lineno, "name": parts[1], "type": "DocGap"}

    return _scan_completist_file("DOCS", _parser)


def analyze_not_implemented() -> list[Finding]:
    """Analyze Not Implemented Error occurrences."""
    ni_str = "NotImplemented" + "Error"

    def _parser(line: str) -> Finding | None:
        f_path, l_no, c_txt = _parse_grep_line(line)
        if f_path and l_no and c_txt and ni_str in c_txt:
            return {"file": f_path, "line": l_no, "text": c_txt, "type": ni_str}
        return None

    return _scan_completist_file("NOT_IMPL", _parser)


def analyze_abstract_methods() -> list[Finding]:
    """Analyze Abstract Methods."""

    def _parser(line: str) -> Finding | None:
        f_path, l_no, c_txt = _parse_grep_line(line)
        if f_path and l_no and c_txt and "@abstractmethod" in c_txt:
            return {"file": f_path, "line": l_no, "text": c_txt, "type": "Abstract"}
        return None

    return _scan_completist_file("ABSTRACT", _parser)


def calculate_metrics(item: Mapping[str, Any]) -> tuple[int, int, int]:
    """Calculate heuristics for Impact, Coverage, and Complexity (1-5 range)."""
    filepath = cast(str, item["file"])
    itype = cast(str, item.get("type", ""))

    impact = (
        5
        if any(x in filepath for x in ["shared/python", "engines/", "api/"])
        else (3 if "tools/" in filepath else 1)
    )
    coverage = 5 if "tests/" in filepath else (3 if "shared/python" in filepath else 2)

    # Complexity mapping
    comp_map = {
        "Stub": 4,
        "NotImplementedError": 4,
        "FIXME": 2,
        "TODO": 3,
        "DocGap": 1,
        "Abstract": 5,
    }
    complexity = comp_map.get(itype, 3)

    return impact, coverage, complexity


def create_issue_file(item: Mapping[str, Any], issue_id: int) -> str:
    """Idempotent creation of markdown issue files."""
    os.makedirs(ISSUES_DIR, exist_ok=True)

    itype = str(item.get("type", "Incomplete Implementation"))
    f_path, l_no = str(item["file"]), str(item["line"])
    context = str(item.get("name", item.get("text", "")))
    title = f"Incomplete {itype} in {os.path.basename(f_path)}:{l_no}"
    fname_title = re.sub(r"[^\w]", "_", title).strip("_")

    # Idempotency check
    existing = glob.glob(os.path.join(ISSUES_DIR, f"Issue_*_{fname_title}.md"))
    if existing:
        return existing[0]

    filepath = os.path.join(ISSUES_DIR, f"Issue_{issue_id:03d}_{fname_title}.md")
    impact, coverage, complexity = calculate_metrics(item)
    labels = ["incomplete-implementation", "critical"]
    if impact >= 5:
        labels.append("high-impact")

    content = f"""---
title: "{title}"
labels: {labels}
assignee: "unassigned"
status: "open"
---

# Issue Description
Found critical incomplete implementation in `{f_path}` at line {l_no}.

## Context
**Type**: {itype} | **Location**: `{f_path}:{l_no}`

```python
{context}
```

## Audit Metrics
- **Impact**: {impact}/5 | **Coverage**: {coverage}/5 | **Complexity**: {complexity}/5

## Recommendation
Implement missing logic or document the rationale for the gap.
"""
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(content)
    return filepath


def generate_mermaid_charts(criticals: list[Finding], todos: list[Finding], fixmes: list[Finding], docs: list[Finding]) -> str:
    """Generate Mermaid charts for the report."""
    chart = []
    chart.append("## Visualization")

    # Pie Chart
    chart.append("### Status Overview")
    chart.append("```mermaid")
    chart.append("pie title Completion Status")
    chart.append(f'    "Impl Gaps (Critical)" : {len(criticals)}')
    chart.append(f'    "Feature Requests (TODO)" : {len(todos)}')
    chart.append(f'    "Technical Debt (FIXME)" : {len(fixmes)}')
    chart.append(f'    "Doc Gaps" : {len(docs)}')
    chart.append("```")

    # Breakdown by Top Modules (Bar Chart equivalent using pie or just text for now as mermaid bar is verbose)
    # Let's do a simple count by top-level dir
    counts = {}
    for item in criticals + todos + fixmes:
        path_parts = item["file"].split("/")
        root = path_parts[0] if path_parts else "unknown"
        if root in [".", "src"]:
            root = path_parts[1] if len(path_parts) > 1 else root
        counts[root] = counts.get(root, 0) + 1

    sorted_mods = sorted(counts.items(), key=lambda x: x[1], reverse=True)[:5]

    if sorted_mods:
        chart.append("\n### Top Impacted Modules")
        chart.append("```mermaid")
        chart.append("pie title Issues by Module")
        for mod, count in sorted_mods:
             chart.append(f'    "{mod}" : {count}')
        chart.append("```")

    return "\n".join(chart)


def generate_report() -> None:
    """Generate the structured completist status report."""
    stubs = analyze_stubs()
    ni_errors = analyze_not_implemented()
    todos, fixmes = analyze_todos()
    missing_docs = analyze_docs()
    _ = analyze_abstract_methods()

    # Identify and prioritize critical candidates
    criticals = [s for s in (stubs + ni_errors) if "test" not in s["file"].lower()]
    criticals.sort(key=lambda x: calculate_metrics(x)[0], reverse=True)

    # Report Generation
    date_s = datetime.now().strftime("%Y-%m-%d")
    report = [
        f"# Completist Report: {date_s}\n",
        "## Executive Summary",
        f"- **Critical Gaps**: {len(criticals)}",
        f"- **Feature Gaps (TODO)**: {len(todos)}",
        f"- **Technical Debt**: {len(fixmes)}",
        f"- **Documentation Gaps**: {len(missing_docs)}\n",
    ]

    # Insert Mermaid Visualization
    report.append(generate_mermaid_charts(criticals, todos, fixmes, missing_docs))

    # Critical Table
    report.append("\n## Critical Incomplete (Top 50)")
    report.append("| File | Line | Type | Impact | Coverage | Complexity |")
    report.append("|---|---|---|---|---|---|")

    for item in criticals[:50]:
        imp, cov, comp = calculate_metrics(item)
        report.append(
            f"| `{item['file']}` | {item['line']} | {item['type']} | {imp} | {cov} | {comp} |"
        )

    # Feature Gap Matrix
    report.append("\n## Feature Gap Matrix")
    report.append("| Module | Feature Gap | Type |")
    report.append("|---|---|---|")
    for item in todos[:50]:
        text = item.get("text", "").replace("|", "\\|")
        report.append(f"| `{item['file']}` | {text[:100]} | {item['type']} |")

    # Technical Debt Register
    report.append("\n## Technical Debt Register")
    report.append("| File | Line | Issue | Type |")
    report.append("|---|---|---|---|")
    for item in fixmes:
        text = item.get("text", "").replace("|", "\\|")
        report.append(
            f"| `{item['file']}` | {item['line']} | {text[:100]} | {item['type']} |"
        )

    # Recommended Implementation Order
    report.append("\n## Recommended Implementation Order")
    report.append("Prioritized by Impact (High) and Complexity (Low).")
    report.append("| Priority | File | Issue | Metrics (I/C/C) |")
    report.append("|---|---|---|---|")

    # Combined list for prioritization
    all_items = criticals + todos

    def priority_score(item: Mapping[str, Any]) -> int:
        imp, _, comp = calculate_metrics(item)
        return (imp * 10) - comp

    all_items.sort(key=priority_score, reverse=True)

    for i, item in enumerate(all_items[:20], 1):
        imp, cov, comp = calculate_metrics(item)
        desc = item.get("name", item.get("text", ""))[:80].replace("|", "\\|")
        report.append(f"| {i} | `{item['file']}` | {desc} | {imp}/{cov}/{comp} |")

    # Issue creation for High Impact items
    report.append("\n## Issues Created")
    max_id = 0
    issues_glob = glob.glob(os.path.join(ISSUES_DIR, "Issue_*.md")) + glob.glob(
        os.path.join(ISSUES_DIR, "ISSUE_*.md")
    )
    for issue_p in issues_glob:
        match_id = re.search(r"(\d+)", os.path.basename(issue_p))
        if match_id:
            max_id = max(max_id, int(match_id.group(1)))

    next_id = max_id + 1
    for item in [c for c in criticals if calculate_metrics(c)[0] >= 4][:10]:
        report.append(f"- Created `{create_issue_file(item, next_id)}`")
        next_id += 1

    os.makedirs(REPORT_DIR, exist_ok=True)
    report_path = os.path.join(REPORT_DIR, f"Completist_Report_{date_s}.md")
    with open(report_path, "w", encoding="utf-8") as f_out:
        f_out.write("\n".join(report))

    latest_path = os.path.join(REPORT_DIR, "COMPLETIST_LATEST.md")
    with open(latest_path, "w", encoding="utf-8") as f_out:
        f_out.write("\n".join(report))

    logger.info("Report generated: %s", report_path)


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    generate_report()
